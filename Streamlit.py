# ğŸ“Š YouTube-Ğ°Ğ½Ğ°Ğ»Ñ–Ñ‚Ğ¸ĞºĞ° Ñƒ Streamlit
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

st.set_page_config(page_title="YouTube Analytics", layout="wide")
st.title("ğŸ“Š YouTube ĞĞ½Ğ°Ğ»Ñ–Ñ‚Ğ¸ĞºĞ° ĞºĞ°Ğ½Ğ°Ğ»Ñ–Ğ²")

# === 1ï¸âƒ£ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ CSV Ğ°Ğ±Ğ¾ Ğ´ĞµĞ¼Ğ¾-Ğ´Ğ°Ğ½Ñ– ===
uploaded = st.file_uploader("Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ CSV (title, views, comments, likes, date, content_type)", type=["csv"])

if uploaded:
    df = pd.read_csv(uploaded)
    st.success("âœ… Ğ”Ğ°Ğ½Ñ– Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ¾!")
else:
    st.info("âš™ï¸ Ğ”Ğ°Ğ½Ñ– Ğ½Ğµ Ğ·Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ¾ â€” ÑÑ‚Ğ²Ğ¾Ñ€ÑÑ Ğ´ĞµĞ¼Ğ¾-Ğ½Ğ°Ğ±Ñ–Ñ€...")
    np.random.seed(0)
    n = 200
    df = pd.DataFrame({
        "title": [f"Video {i+1}" for i in range(n)],
        "views": np.random.randint(100, 20000, n),
        "comments": np.random.randint(0, 500, n),
        "likes": np.random.randint(0, 3000, n),
        "date": [datetime(2025,1,1) + timedelta(days=np.random.randint(0,280),
                                                hours=np.random.randint(0,24)) for _ in range(n)],
        "content_type": np.random.choice(["Shorts", "Long-form", "Stream"], n)
    })

# === 2ï¸âƒ£ ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ´Ğ°Ğ½Ğ¸Ñ… ===
df['date'] = pd.to_datetime(df['date'])
df['day_of_week'] = df['date'].dt.day_name()
df['hour'] = df['date'].dt.hour

# === 3ï¸âƒ£ Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ¸ ===
col1, col2, col3 = st.columns(3)

with col1:
    start_date = st.date_input("ĞŸĞ¾Ñ‡Ğ°Ñ‚ĞºĞ¾Ğ²Ğ° Ğ´Ğ°Ñ‚Ğ°", df['date'].min().date())
with col2:
    end_date = st.date_input("ĞšÑ–Ğ½Ñ†ĞµĞ²Ğ° Ğ´Ğ°Ñ‚Ğ°", df['date'].max().date())
with col3:
    content_filter = st.selectbox("Ğ¢Ğ¸Ğ¿ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ñƒ", ["Ğ£ÑÑ–"] + sorted(df['content_type'].unique().tolist()))

filtered = df[(df['date'] >= pd.to_datetime(start_date)) & (df['date'] <= pd.to_datetime(end_date))]
if content_filter != "Ğ£ÑÑ–":
    filtered = filtered[filtered['content_type'] == content_filter]

# === 4ï¸âƒ£ Engagement rate ===
filtered['engagement_rate'] = ((filtered['likes'] + filtered['comments']) / filtered['views'].replace(0, np.nan)) * 100
eng_avg = filtered['engagement_rate'].mean()

st.metric("ğŸ“ˆ Ğ¡ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ engagement rate", f"{eng_avg:.2f}%")
st.write(f"Ğ’Ñ–Ğ´ĞµĞ¾ Ñƒ Ğ²Ğ¸Ğ±Ñ–Ñ€Ñ†Ñ–: **{len(filtered)}**")

# === 5ï¸âƒ£ Heatmap Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ñ– ===
st.subheader("ğŸ”¥ Heatmap Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ñ– (ÑĞµÑ€ĞµĞ´Ğ½Ñ– Ğ¿ĞµÑ€ĞµĞ³Ğ»ÑĞ´Ğ¸)")
pivot = filtered.groupby(['day_of_week','hour'])['views'].mean().unstack(fill_value=0)
pivot = pivot.reindex(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])

fig, ax = plt.subplots(figsize=(10,5))
sns.heatmap(pivot, cmap='YlOrRd', linewidths=.5, ax=ax)
plt.xlabel("Ğ“Ğ¾Ğ´Ğ¸Ğ½Ğ° Ğ´Ğ½Ñ")
plt.ylabel("Ğ”ĞµĞ½ÑŒ Ñ‚Ğ¸Ğ¶Ğ½Ñ")
st.pyplot(fig)

# === 6ï¸âƒ£ Ğ¢Ğ¾Ğ¿-10 Ğ·Ğ° engagement rate ===
st.subheader("ğŸ† Ğ¢Ğ¾Ğ¿-10 Ğ²Ñ–Ğ´ĞµĞ¾ Ğ·Ğ° engagement rate")
top10 = filtered.sort_values('engagement_rate', ascending=False).head(10)
st.dataframe(top10[['title','views','likes','comments','engagement_rate']])

# === 7ï¸âƒ£ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ² ===
csv = filtered.to_csv(index=False).encode('utf-8')
st.download_button("ğŸ’¾ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸ (CSV)", csv, "youtube_analysis.csv", "text/csv")

st.success("âœ… ĞĞ½Ğ°Ğ»Ñ–Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾!")
